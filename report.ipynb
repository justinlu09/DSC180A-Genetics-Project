{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the pre-processing pipeline, a symbolic link should be made between this repo's `/data/raw` directory and the user's machine. #TODO\n",
    "\n",
    "In our data processing pipeline, we load in pairs of `.fastq.gz` files for each brain sample. For each pair of `SRRXXXXXXX_1.fastq.gz` and `SRRXXXXXXX_2.fastq.gz` file, we must perform quality control on them to ensure that they are good quality samples. Here, we use the `FastQC` software to ensure that they are good-quality RNA-seq read data. \n",
    "\n",
    "Then, we use the `cutadapt` tool to remove irrelevant parts of the read, like 3' adapters that can be added during the RNA-seq process, or even entire reads if they are bad-quality reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in our pre-processing pipeline involves using `FastQC` on each `fastq.gz` file. For the purposes of Checkpoint 2, we performed quality checks using `FastQC` on a sample of 10 files (5 pairs of samples).\n",
    "\n",
    "Here is the sample input parameters and output of `FastQC` on a pair of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fq_location = '/opt/FastQC/fastqc'\n",
    "# os.system(fq_location + ' /datasets/srp073813/SRR3438555_1.fastq.gz /datasets/srp073813/SRR3438555_2.fastq.gz'\n",
    "#          + ' --outdir /datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample `FastQC` output:\n",
    "\n",
    "<img src=\"images/FastqcSample.png\" width=\"550px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SRR3438555_1_fastqc.html',\n",
       " 'SRR3438555_1_fastqc.zip',\n",
       " 'SRR3438555_2_fastqc.html',\n",
       " 'SRR3438555_2_fastqc.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fq_output = []\n",
    "for i in os.listdir('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_test'):\n",
    "    if i.endswith('zip') or i.endswith('html'):\n",
    "        fq_output.append(i)\n",
    "sorted(fq_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from one `FastQC` run, the software outputs a `.zip` file with specific information on the run, as well as an overall report of the quality of the sample in an `.html` file.\n",
    "\n",
    "Below, we will work on the sample of 10 files that we have already ran using our `run.py` script. \n",
    "\n",
    "We first look at the the HTML reports that `FastQC` generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SRR3438555_1_fastqc.html',\n",
       " 'SRR3438555_2_fastqc.html',\n",
       " 'SRR3438556_1_fastqc.html',\n",
       " 'SRR3438556_2_fastqc.html',\n",
       " 'SRR3438557_1_fastqc.html',\n",
       " 'SRR3438557_2_fastqc.html',\n",
       " 'SRR3438558_1_fastqc.html',\n",
       " 'SRR3438558_2_fastqc.html',\n",
       " 'SRR3438559_1_fastqc.html',\n",
       " 'SRR3438559_2_fastqc.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastqc_files = os.listdir('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_temp_bc')\n",
    "htmls = []\n",
    "for i in sorted(fastqc_files):\n",
    "    if i.endswith('html'):\n",
    "        htmls.append(i)\n",
    "htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SRR3438555_1_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438555_2_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438556_1_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438556_2_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438557_1_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438557_2_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438558_1_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438558_2_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438559_1_fastqc.html': 'No overrepresented sequences',\n",
       " 'SRR3438559_2_fastqc.html': 'No overrepresented sequences'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_check = {}\n",
    "for i in htmls:\n",
    "    fastqc_path = '/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_temp_bc'\n",
    "    path = os.path.join(fastqc_path, i)\n",
    "    soup = BeautifulSoup(open(path), 'html.parser')\n",
    "    check = soup.find_all('div', attrs= {'class':\"module\"})[8].find('p').text\n",
    "    adapter_check[i] = check\n",
    "adapter_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, we can conclude `FastQC` confirms that our reads do not include 'overrepresented sequences', which are normally sequences not found in the human genome, possibly 3' adapters or erroneous sequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we process the `.zip` files, which contain the specific metadata of each read. We will look specifically at the `fastqc_data.txt` file that is generated by each run of `FastQC`, which includes basic statistics on the run, sequence qualities, and most importantly, a 'pass/fail' flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = []\n",
    "for i in sorted(fastqc_files):\n",
    "    if i.endswith('zip'):\n",
    "        zips.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zips:\n",
    "    fastqc_path = '/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_temp_bc'\n",
    "    zip_path = os.path.join(fastqc_path, i)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_test', i.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SRR3438555_1_fastqc': 'pass',\n",
       " 'SRR3438555_2_fastqc': 'pass',\n",
       " 'SRR3438556_1_fastqc': 'pass',\n",
       " 'SRR3438556_2_fastqc': 'pass',\n",
       " 'SRR3438557_1_fastqc': 'pass',\n",
       " 'SRR3438557_2_fastqc': 'pass',\n",
       " 'SRR3438558_1_fastqc': 'pass',\n",
       " 'SRR3438558_2_fastqc': 'pass',\n",
       " 'SRR3438559_1_fastqc': 'pass',\n",
       " 'SRR3438559_2_fastqc': 'pass'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zippers = os.listdir('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_test')\n",
    "pass_check = {}\n",
    "for i in sorted(zippers):\n",
    "    if (i.endswith('html')==False) and (i.endswith('zip')==False) and (i.endswith('points')==False):\n",
    "        zippers_path = '/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/fastqc_test'\n",
    "        path = os.path.join(zippers_path, i, i, 'fastqc_data.txt')\n",
    "        f = open(path, 'r')\n",
    "        pass_check[i] = f.readlines()[1][-5:-1]\n",
    "pass_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metadata confirms that our reads are good-quality reads. As stated above, if there are low-quality reads or sequences, we should use `cutadapt` to remove the sub-standard reads. Since `FastQC` tells us that all the reads have no overrepresented sequences (aka adapters) and that all our reads passed the \"pass/fail\" check, we may not need to run `cutadapt` for these sample reads, because there is nothing extraneous to remove. This may not be true for **all** our reads, though, so we should still run it to be safe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cutadapt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of `FastQC`, most of our samples are 'clean', which means that it does not have any bad sequence reads. However, for demonstration purposes, we still want to show how to utilize `cutadapt` for the purpose of cutting away the adapters and bad sequences.\n",
    "\n",
    "Here, we need both reads of a pair of samples; the adapter parameters in the `-a` and the `-A` are default adapters (`AACCGGTT`); these may differ based on the read and what adapters were used (specifically the ones added during the Illumina process):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 3.0 with Python 3.7.6\n",
      "Command line parameters: -a AACCGGTT -A AACCGGTT -o /datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/notebooks/cutadapt_test/out.1.fastq.gz -p /datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/notebooks/cutadapt_test/out.2.fastq.gz /datasets/srp073813/SRR3438555_1.fastq.gz /datasets/srp073813/SRR3438555_2.fastq.gz --cores=8\n",
      "Processing reads on 8 cores in paired-end mode ...\n",
      "Finished in 494.38 s (12 µs/read; 5.07 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total read pairs processed:         41,776,033\n",
      "  Read 1 with adapter:                 712,945 (1.7%)\n",
      "  Read 2 with adapter:                 708,182 (1.7%)\n",
      "Pairs written (passing filters):    41,776,033 (100.0%)\n",
      "\n",
      "Total basepairs processed: 4,177,603,300 bp\n",
      "  Read 1: 2,088,801,650 bp\n",
      "  Read 2: 2,088,801,650 bp\n",
      "Total written (filtered):  4,172,794,169 bp (99.9%)\n",
      "  Read 1: 2,086,387,399 bp\n",
      "  Read 2: 2,086,406,770 bp\n",
      "\n",
      "=== First read: Adapter 1 ===\n",
      "\n",
      "Sequence: AACCGGTT; Type: regular 3'; Length: 8; Trimmed: 712945 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-8 bp: 0\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 31.8%\n",
      "  C: 26.7%\n",
      "  G: 25.4%\n",
      "  T: 16.1%\n",
      "  none/other: 0.0%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t549516\t652750.5\t0\t549516\n",
      "4\t144870\t163187.6\t0\t144870\n",
      "5\t11512\t40796.9\t0\t11512\n",
      "6\t2605\t10199.2\t0\t2605\n",
      "7\t447\t2549.8\t0\t447\n",
      "8\t104\t637.5\t0\t104\n",
      "9\t120\t637.5\t0\t120\n",
      "10\t115\t637.5\t0\t115\n",
      "11\t61\t637.5\t0\t61\n",
      "12\t96\t637.5\t0\t96\n",
      "13\t100\t637.5\t0\t100\n",
      "14\t193\t637.5\t0\t193\n",
      "15\t65\t637.5\t0\t65\n",
      "16\t131\t637.5\t0\t131\n",
      "17\t49\t637.5\t0\t49\n",
      "18\t78\t637.5\t0\t78\n",
      "19\t137\t637.5\t0\t137\n",
      "20\t80\t637.5\t0\t80\n",
      "21\t80\t637.5\t0\t80\n",
      "22\t98\t637.5\t0\t98\n",
      "23\t65\t637.5\t0\t65\n",
      "24\t140\t637.5\t0\t140\n",
      "25\t134\t637.5\t0\t134\n",
      "26\t94\t637.5\t0\t94\n",
      "27\t75\t637.5\t0\t75\n",
      "28\t90\t637.5\t0\t90\n",
      "29\t130\t637.5\t0\t130\n",
      "30\t99\t637.5\t0\t99\n",
      "31\t70\t637.5\t0\t70\n",
      "32\t81\t637.5\t0\t81\n",
      "33\t106\t637.5\t0\t106\n",
      "34\t109\t637.5\t0\t109\n",
      "35\t111\t637.5\t0\t111\n",
      "36\t100\t637.5\t0\t100\n",
      "37\t89\t637.5\t0\t89\n",
      "38\t56\t637.5\t0\t56\n",
      "39\t93\t637.5\t0\t93\n",
      "40\t109\t637.5\t0\t109\n",
      "41\t98\t637.5\t0\t98\n",
      "42\t31\t637.5\t0\t31\n",
      "43\t34\t637.5\t0\t34\n",
      "44\t230\t637.5\t0\t230\n",
      "45\t166\t637.5\t0\t166\n",
      "46\t68\t637.5\t0\t68\n",
      "47\t24\t637.5\t0\t24\n",
      "48\t7\t637.5\t0\t7\n",
      "49\t37\t637.5\t0\t37\n",
      "50\t42\t637.5\t0\t42\n",
      "\n",
      "\n",
      "=== Second read: Adapter 2 ===\n",
      "\n",
      "Sequence: AACCGGTT; Type: regular 3'; Length: 8; Trimmed: 708182 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-8 bp: 0\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 31.8%\n",
      "  C: 26.7%\n",
      "  G: 25.5%\n",
      "  T: 16.1%\n",
      "  none/other: 0.0%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t545305\t652750.5\t0\t545305\n",
      "4\t144424\t163187.6\t0\t144424\n",
      "5\t11561\t40796.9\t0\t11561\n",
      "6\t2627\t10199.2\t0\t2627\n",
      "7\t433\t2549.8\t0\t433\n",
      "8\t87\t637.5\t0\t87\n",
      "9\t138\t637.5\t0\t138\n",
      "10\t120\t637.5\t0\t120\n",
      "11\t60\t637.5\t0\t60\n",
      "12\t72\t637.5\t0\t72\n",
      "13\t107\t637.5\t0\t107\n",
      "14\t170\t637.5\t0\t170\n",
      "15\t78\t637.5\t0\t78\n",
      "16\t112\t637.5\t0\t112\n",
      "17\t52\t637.5\t0\t52\n",
      "18\t63\t637.5\t0\t63\n",
      "19\t123\t637.5\t0\t123\n",
      "20\t74\t637.5\t0\t74\n",
      "21\t88\t637.5\t0\t88\n",
      "22\t95\t637.5\t0\t95\n",
      "23\t89\t637.5\t0\t89\n",
      "24\t142\t637.5\t0\t142\n",
      "25\t125\t637.5\t0\t125\n",
      "26\t89\t637.5\t0\t89\n",
      "27\t86\t637.5\t0\t86\n",
      "28\t115\t637.5\t0\t115\n",
      "29\t115\t637.5\t0\t115\n",
      "30\t81\t637.5\t0\t81\n",
      "31\t81\t637.5\t0\t81\n",
      "32\t76\t637.5\t0\t76\n",
      "33\t113\t637.5\t0\t113\n",
      "34\t70\t637.5\t0\t70\n",
      "35\t115\t637.5\t0\t115\n",
      "36\t75\t637.5\t0\t75\n",
      "37\t79\t637.5\t0\t79\n",
      "38\t72\t637.5\t0\t72\n",
      "39\t87\t637.5\t0\t87\n",
      "40\t126\t637.5\t0\t126\n",
      "41\t43\t637.5\t0\t43\n",
      "42\t24\t637.5\t0\t24\n",
      "43\t35\t637.5\t0\t35\n",
      "44\t270\t637.5\t0\t270\n",
      "45\t138\t637.5\t0\t138\n",
      "46\t39\t637.5\t0\t39\n",
      "47\t23\t637.5\t0\t23\n",
      "48\t9\t637.5\t0\t9\n",
      "49\t40\t637.5\t0\t40\n",
      "50\t36\t637.5\t0\t36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.system('cutadapt -a AACCGGTT -A AACCGGTT ' + \n",
    "          '-o /datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/cutadapt_test/out.1.fastq.gz ' +\n",
    "          '-p /datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/cutadapt_test/out.2.fastq.gz ' +\n",
    "          '/datasets/srp073813/SRR3438555_1.fastq.gz ' +\n",
    "          '/datasets/srp073813/SRR3438555_2.fastq.gz --cores=8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://biopython.org/wiki/GFF_Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out.2.fastq.gz', 'out.1.fastq.gz', 'report.txt']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/cutadapt_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After quality control of the data is finished, we need to perform alignment of each of the pairs to \"combine\" the information of the paired-end data. This allows us to quantify the expressions of the reads. To do the alignment, we have decided to use the `Kallisto` tool. Using a reference genome generated by `Kallisto`, we perform alignment of the RNA samples to quantify gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(os.popen(\"/opt/kallisto_linux-v0.42.4/kallisto quant \" +\n",
    "               \"-i /datasets/srp073813/reference/kallisto_transcripts.idx -b 30 \"\n",
    "               \"-o /datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/kallisto_test \" +\n",
    "               \"/datasets/srp073813/SRR3438555_1.fastq.gz \" + \n",
    "               \"/datasets/srp073813/SRR3438555_2.fastq.gz\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GRCh37_latest_genomic.gff',\n",
       " 'GRCh37_latest_rna.fa.gz',\n",
       " 'GRCh37_latest_genomic.fa.gz',\n",
       " 'kallisto_transcripts.idx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/datasets/srp073813/reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_info.json', 'abundance.h5', 'abundance.tsv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/kallisto_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>length</th>\n",
       "      <th>eff_length</th>\n",
       "      <th>est_counts</th>\n",
       "      <th>tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NM_000014.6</td>\n",
       "      <td>4610</td>\n",
       "      <td>4438.490</td>\n",
       "      <td>3747.5600</td>\n",
       "      <td>75.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NM_000015.3</td>\n",
       "      <td>1285</td>\n",
       "      <td>1113.490</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NM_000016.6</td>\n",
       "      <td>2261</td>\n",
       "      <td>2089.490</td>\n",
       "      <td>392.9280</td>\n",
       "      <td>16.719700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NM_000017.4</td>\n",
       "      <td>1859</td>\n",
       "      <td>1687.490</td>\n",
       "      <td>371.8200</td>\n",
       "      <td>19.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NM_000018.4</td>\n",
       "      <td>2184</td>\n",
       "      <td>2012.490</td>\n",
       "      <td>4365.3100</td>\n",
       "      <td>192.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78746</th>\n",
       "      <td>NR_170930.1</td>\n",
       "      <td>5594</td>\n",
       "      <td>5422.490</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78747</th>\n",
       "      <td>NR_170931.1</td>\n",
       "      <td>5401</td>\n",
       "      <td>5229.490</td>\n",
       "      <td>25.9308</td>\n",
       "      <td>0.440872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78748</th>\n",
       "      <td>NR_170932.1</td>\n",
       "      <td>623</td>\n",
       "      <td>452.071</td>\n",
       "      <td>61.1665</td>\n",
       "      <td>12.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78749</th>\n",
       "      <td>NR_170933.1</td>\n",
       "      <td>1086</td>\n",
       "      <td>914.488</td>\n",
       "      <td>7.9105</td>\n",
       "      <td>0.769098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78750</th>\n",
       "      <td>NR_170934.1</td>\n",
       "      <td>679</td>\n",
       "      <td>507.875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78751 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target_id  length  eff_length  est_counts         tpm\n",
       "0      NM_000014.6    4610    4438.490   3747.5600   75.070500\n",
       "1      NM_000015.3    1285    1113.490      0.0000    0.000000\n",
       "2      NM_000016.6    2261    2089.490    392.9280   16.719700\n",
       "3      NM_000017.4    1859    1687.490    371.8200   19.590600\n",
       "4      NM_000018.4    2184    2012.490   4365.3100  192.858000\n",
       "...            ...     ...         ...         ...         ...\n",
       "78746  NR_170930.1    5594    5422.490      0.0000    0.000000\n",
       "78747  NR_170931.1    5401    5229.490     25.9308    0.440872\n",
       "78748  NR_170932.1     623     452.071     61.1665   12.029900\n",
       "78749  NR_170933.1    1086     914.488      7.9105    0.769098\n",
       "78750  NR_170934.1     679     507.875      0.0000    0.000000\n",
       "\n",
       "[78751 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abundance = pd.read_csv('/datasets/home/home-01/33/333/jll020/dsc180a-b04-group04/data/raw/kallisto_test/abundance.tsv', sep='\\t')\n",
    "abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picard is used to perform quality control on the alignment done by Kallisto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeSEQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-based tool, DeSEQ2, performs gene differential expression analysis on the output of the alignment. The tool normalizes the output of the alignment and returns the counts for each gene in the alignment, giving us informtation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
